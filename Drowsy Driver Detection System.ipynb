{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4772d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from threading import Thread\n",
    "import playsound\n",
    "import queue\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f4fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_DOWNSAMPLE_RATIO = 1.5\n",
    "RESIZE_HEIGHT = 460\n",
    "thresh = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c77f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"/Users/triptibhardwaj/Downloads/shape_predictor_68_face_landmarks.dat\"\n",
    "sound_path = \"/Users/triptibhardwaj/Downloads/alarm.wav\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34672d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftEyeIndex = [36, 37, 38, 39, 40, 41]\n",
    "rightEyeIndex = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "blinkCount = 0\n",
    "drowsy = 0\n",
    "state = 0\n",
    "blinkTime = 0.15 #150ms\n",
    "drowsyTime = 1.0  #1200ms\n",
    "ALARM_ON = False\n",
    "GAMMA = 1.5\n",
    "ALARM_START_TIME = None\n",
    "alarm_thread = None\n",
    "threadStatusQ = queue.Queue()\n",
    "invGamma = 1.0/GAMMA\n",
    "table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36220bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(image):\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b686cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.equalizeHist(gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c346513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soundAlert(path, threadStatusQ):\n",
    "    global ALARM_ON, ALARM_START_TIME\n",
    "    \n",
    "    while ALARM_ON:\n",
    "        if not threadStatusQ.empty():\n",
    "            FINISHED = threadStatusQ.get()\n",
    "            if FINISHED:\n",
    "                break\n",
    "        \n",
    "        if ALARM_START_TIME is not None:\n",
    "            elapsed_time = time.time() - ALARM_START_TIME\n",
    "            if elapsed_time >= 3.0:  \n",
    "                ALARM_ON = False \n",
    "        playsound.playsound(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b5886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53607cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEyeStatus(landmarks):\n",
    "    mask = np.zeros(frame.shape[:2], dtype = np.float32)\n",
    "    \n",
    "    hullLeftEye = []\n",
    "    for i in range(0, len(leftEyeIndex)):\n",
    "        hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n",
    "\n",
    "    hullRightEye = []\n",
    "    for i in range(0, len(rightEyeIndex)):\n",
    "        hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n",
    "\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n",
    "    leftEAR = eye_aspect_ratio(hullLeftEye)\n",
    "    rightEAR = eye_aspect_ratio(hullRightEye)\n",
    "\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    \n",
    "    eyeStatus = 1          # 1 -> Open, 0 -> closed\n",
    "    if (ear < thresh):\n",
    "        eyeStatus = 0\n",
    "    return eyeStatus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1db4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBlinkStatus(eyeStatus):\n",
    "    global state, blinkCount, drowsy\n",
    "    if(state >= 0 and state <= falseBlinkLimit):\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "        else:\n",
    "            state += 1\n",
    "    elif(state >= falseBlinkLimit and state < drowsyLimit):\n",
    "        if(eyeStatus):\n",
    "            blinkCount += 1 \n",
    "            state = 0\n",
    "        else:\n",
    "            state += 1\n",
    "    else:\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "            drowsy = 1\n",
    "            blinkCount += 1\n",
    "        else:\n",
    "            drowsy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52e67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLandmarks(im):\n",
    "    imSmall = cv2.resize(im, None, \n",
    "                            fx = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            fy = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    rects = detector(imSmall, 0)\n",
    "    if len(rects) == 0:\n",
    "        return 0\n",
    "\n",
    "    newRect = dlib.rectangle(int(rects[0].left() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].top() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].right() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].bottom() * FACE_DOWNSAMPLE_RATIO))\n",
    "\n",
    "    points = []\n",
    "    [points.append((p.x, p.y)) for p in predictor(im, newRect).parts()]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9de51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caliberation in Progress!\n",
      "Caliberation Complete!\n",
      "Current SPF (seconds per frame) is 33.27 ms\n",
      "drowsy limit: 30.059002821500158, false blink limit: 4.508850423225024\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "totalTime = 0.0\n",
    "validFrames = 0\n",
    "dummyFrames = 100\n",
    "\n",
    "print(\"Caliberation in Progress!\")\n",
    "while(validFrames < dummyFrames):\n",
    "    validFrames += 1\n",
    "    t = time.time()\n",
    "    ret, frame = capture.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "    frame = cv2.resize(frame, None, \n",
    "                        fx = 1/IMAGE_RESIZE, \n",
    "                        fy = 1/IMAGE_RESIZE, \n",
    "                        interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    adjusted = histogram_equalization(frame)\n",
    "\n",
    "    landmarks = getLandmarks(adjusted)\n",
    "    timeLandmarks = time.time() - t\n",
    "\n",
    "    if landmarks == 0:\n",
    "        validFrames -= 1\n",
    "        cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            sys.exit()\n",
    "\n",
    "    else:\n",
    "        totalTime += timeLandmarks\n",
    "print(\"Caliberation Complete!\")\n",
    "\n",
    "spf = totalTime/dummyFrames\n",
    "print(\"Current SPF (seconds per frame) is {:.2f} ms\".format(spf * 1000))\n",
    "\n",
    "drowsyLimit = drowsyTime/spf\n",
    "falseBlinkLimit = blinkTime/spf\n",
    "print(\"drowsy limit: {}, false blink limit: {}\".format(drowsyLimit, falseBlinkLimit))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vid_writer = cv2.VideoWriter('output-low-light-2.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    while(1):\n",
    "        try:\n",
    "            t = time.time()\n",
    "            ret, frame = capture.read()\n",
    "            height, width = frame.shape[:2]\n",
    "            IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "            frame = cv2.resize(frame, None, \n",
    "                                fx = 1/IMAGE_RESIZE, \n",
    "                                fy = 1/IMAGE_RESIZE, \n",
    "                                interpolation = cv2.INTER_LINEAR)\n",
    "            adjusted = histogram_equalization(frame)\n",
    "\n",
    "            landmarks = getLandmarks(adjusted)\n",
    "            if landmarks == 0:\n",
    "                validFrames -= 1\n",
    "                cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            eyeStatus = checkEyeStatus(landmarks)\n",
    "            checkBlinkStatus(eyeStatus)\n",
    "\n",
    "            for i in range(0, len(leftEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            for i in range(0, len(rightEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            if drowsy:\n",
    "                cv2.putText(frame, \"! ! ! DROWSINESS ALERT ! ! !\", (70, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                if not ALARM_ON:\n",
    "                    ALARM_ON = True\n",
    "                    ALARM_START_TIME = time.time()  # Record the start time\n",
    "                    threadStatusQ.put(not ALARM_ON)\n",
    "                    thread = Thread(target=soundAlert, args=(sound_path, threadStatusQ,))\n",
    "                    thread.setDaemon(True)\n",
    "                    thread.start()\n",
    "\n",
    "            else:\n",
    "                cv2.putText(frame, \"Blinks : {}\".format(blinkCount), (460, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "                ALARM_ON = False\n",
    "\n",
    "\n",
    "            cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "            vid_writer.write(frame)\n",
    "\n",
    "            k = cv2.waitKey(1) \n",
    "            if k == ord('r'):\n",
    "                state = 0\n",
    "                drowsy = 0\n",
    "                ALARM_ON = False\n",
    "                threadStatusQ.put(False)\n",
    "                ALARM_START_TIME = None  \n",
    "            elif k == 27:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    capture.release()\n",
    "    vid_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
